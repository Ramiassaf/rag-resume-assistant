{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa658bcd",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e3771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\rami\\envs\\rag_resume\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community .document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ecdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_dir = Path(r\"C:\\Users\\user\\Desktop\\HRbotassistance\\resumedata\")\n",
    "assert Data_dir.exists(), f\"Folder not found {Data_dir()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b8ce8",
   "metadata": {},
   "source": [
    "# Load PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aae8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41 documents\n",
      "Sample text: Khalid Nassar\n",
      "Deep Learning Engineer — Riyadh, Saudi Arabia\n",
      "Email: khalid.nassar1@example.com | Phone: +966592881653\n",
      "Professional Summary\n",
      "Experienced Deep Learning Engineer with a strong track record of building production-grade machine\n",
      "learning systems, from data engineering and model training to d\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for pdf in Data_dir.glob(\"*.pdf\"):\n",
    "    loader = PyMuPDFLoader(str(pdf))\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "print(\"Sample text:\" , docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23d376",
   "metadata": {},
   "source": [
    "# Split into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f10d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 181 chunks\n",
      "Sample chunk: Khalid Nassar\n",
      "Deep Learning Engineer — Riyadh, Saudi Arabia\n",
      "Email: khalid.nassar1@example.com | Phone: +966592881653\n",
      "Professional Summary\n",
      "Experienced Deep Learning Engineer with a strong track record of building production-grade machine\n",
      "learning systems, from data engineering and model training to d\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, # maximum size of each chunk\n",
    "    chunk_overlap=50 # overlap so contecxt is maintained\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(\"Sample chunk:\" , chunks[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe1046",
   "metadata": {},
   "source": [
    "# Embed and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7180\\1352474380.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings= HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings= HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
    "# create vector store\n",
    "db = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = embeddings,\n",
    "    collection_name = \"resumes\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da70e3b",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eca7a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] {'creationDate': \"D:20250930175541+00'00'\", 'modDate': \"D:20250930175541+00'00'\", 'creator': '(unspecified)', 'title': '(anonymous)', 'creationdate': '2025-09-30T17:55:41+00:00', 'producer': 'ReportLab PDF Library - www.reportlab.com', 'keywords': '', 'author': '(anonymous)', 'source': 'C:\\\\Users\\\\user\\\\Desktop\\\\HRbotassistance\\\\resumedata\\\\ai_resume_realistic_01_Khalid_Nassar.pdf', 'format': 'PDF 1.4', 'trapped': '', 'moddate': '2025-09-30T17:55:41+00:00', 'subject': '(unspecified)', 'file_path': 'C:\\\\Users\\\\user\\\\Desktop\\\\HRbotassistance\\\\resumedata\\\\ai_resume_realistic_01_Khalid_Nassar.pdf', 'total_pages': 1, 'page': 0}\n",
      "post-processing to extract structured candidate data.\n",
      "• Optimized model inference using TensorRT and mixed precision; achieved 2.5x throughput improvement\n",
      "on GPU.\n",
      "Education\n",
      "MSc in Computer Science, Machine Learning Track — University of Technology, 2019\n",
      "Certifications\n",
      "• AWS Certified Machine Learnin\n",
      "\n",
      "[2] {'creationdate': '2025-09-30T17:55:41+00:00', 'title': '(anonymous)', 'subject': '(unspecified)', 'format': 'PDF 1.4', 'page': 0, 'creationDate': \"D:20250930175541+00'00'\", 'keywords': '', 'file_path': 'C:\\\\Users\\\\user\\\\Desktop\\\\HRbotassistance\\\\resumedata\\\\ai_resume_realistic_17_Sara_Elhaj.pdf', 'modDate': \"D:20250930175541+00'00'\", 'total_pages': 1, 'source': 'C:\\\\Users\\\\user\\\\Desktop\\\\HRbotassistance\\\\resumedata\\\\ai_resume_realistic_17_Sara_Elhaj.pdf', 'creator': '(unspecified)', 'moddate': '2025-09-30T17:55:41+00:00', 'trapped': '', 'author': '(anonymous)', 'producer': 'ReportLab PDF Library - www.reportlab.com'}\n",
      "Certifications\n",
      "• TensorFlow Developer Certificate\n",
      "• AWS Certified Machine Learning – Specialty\n",
      "Languages\n",
      "English (Fluent), French (Conversational)\n",
      "Generated sample resume — 2025-09-30\n"
     ]
    }
   ],
   "source": [
    "query = \"Find candidates with Tensorflow and AWS experience\"\n",
    "results = db.similarity_search(query, k=2)\n",
    "\n",
    "for i, r in enumerate(results, start=1):\n",
    "    print(f\"\\n[{i}] {r.metadata}\")\n",
    "    print(r.page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d025d74",
   "metadata": {},
   "source": [
    "# Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3390e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e06e75f",
   "metadata": {},
   "source": [
    "### Import LLM From Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e670433",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text_generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.2,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefeff2",
   "metadata": {},
   "source": [
    "### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd99ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query, db, k=3):\n",
    "    # retrieve relevant documents\n",
    "    results = db.similarity_search(query, k=k)\n",
    "    context = \"\\n\\n\".join([r.page_content for r in results])\n",
    "\n",
    "    # create prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI HR assistant\n",
    "    Here are some candidate resumes:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    Answer clearly and concisely, citing relevant experience from resumes.PermissionError\n",
    "    \"\"\"\n",
    "\n",
    "    # generate response\n",
    "    output = generator(prompt)[0][\"generated_text\"]\n",
    "    return output\n",
    "\n",
    "\n",
    "# Example\n",
    "answer = rag_answer(\"Find candidates with TensorFlow and AWS experience\", db)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
